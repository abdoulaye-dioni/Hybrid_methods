---
title: "simulation_support_data"
output: 
  html_document: 
    toc: true
    highlight: tango
    theme: cerulean
    number_sections: true
date: "`r Sys.Date()`"
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(
  message = FALSE, 
  warning = FALSE, 
  fig.keep = "none"
)
```




```{r}
ti <- Sys.time()


library(Hmisc)
library(survival)
#library(ggthemes)
library(parallel)
library(mice)
library(mitml)
library(splines)
#library(survminer)

```




## Loading the Data

```{r}
getHdata(support)
getHdata(support2)
support.name <- names(support)
support.name
```

Restricted variable selection was performed according to the recommendations provided on hbiostat.org/data/repo/supportdesc.

```{r}
support2_data <- support2[, support.name] 
dim(support2_data)
```




```{r}
support2_data <- as.data.frame(lapply(support2_data, function(col) {
  if (inherits(col, "labelled")) {
    return(as.vector(col))
  } else {
    return(col)
  }
}))

```


```{r}
dim(support2_data)
names(support2_data)
```


```{r}
summary(support2_data)
```

As part of the illustration of hybrid approaches, the analysis is restricted to a subset of clinically relevant variables measured at admission.



```{r}
support2_data <- support2_data[, c("d.time","death","age","sex","income","sod", "resp")]

```


```{r}
summary(support2_data)
```


```{r}
support2_data$income <- as.character(support2_data$income)
support2_data$income[support2_data$income %in% c("$25-$50k", ">$50k")] <- ">$25k"
support2_data$income <- factor(support2_data$income,
                            levels = c("under $11k", "$11-$25k" ,   ">$25k"),
                            labels = c("<11k", "11–25k", ">25k")
)
```


```{r}
support2_data$resp <- ifelse(support2_data$resp == 0, NA, support2_data$resp)
support2_data <- support2_data[!support2_data$resp %in% c(0), ]
support2_data$death <- as.factor(support2_data$death)
support2_data$d.time <- support2_data$d.time/(30.4375*3) 
```

```{r}
dim(support2_data)
```





 
 Initial logistic model to predict the probability of observing 'income'. Stepwise selection based on the AIC criterion is used to identify the most parsimonious and best-fitting model.

```{r}
support2_data$R.income <- as.factor(ifelse(is.na(support2_data$income),0,1))
vars <- c("R.income", "age", "sex", "death", "d.time", "resp", "sod")
support2_data <- support2_data[complete.cases(support2_data[, vars]), ]

mis_mod <- MASS::stepAIC(
  glm(R.income ~ age + sex + death + d.time + resp + sod,
      data = support2_data,
      family = binomial),
  direction = "both",
  trace = FALSE
)


summary(mis_mod)
```



The predictors of missingness in `income` sont `age`, `death` and `sod`


## Complete data available for analysis


```{r}
mydata <- support2_data[complete.cases(support2_data), ]
dim(mydata)

```


# Assessment of the linearity of continuous variables

```{r}
smoothSEcurve <- function(yy, xx) {
  xx.list <- min(xx) + ((0:100)/100)*(max(xx) - min(xx))
  yy.xx <- predict(loess(yy ~ xx), se=T,
                   newdata=data.frame(xx=xx.list))
  lines(yy.xx$fit ~ xx.list, lwd=2,pch = 19, col = "red")
  lines(yy.xx$fit -
          qt(0.975, yy.xx$df)*yy.xx$se.fit ~ xx.list, lwd=2, lty=2,col = "blue")
  lines(yy.xx$fit +
          qt(0.975, yy.xx$df)*yy.xx$se.fit ~ xx.list,lwd=2, lty=2, col = "blue")
}

```


```{r}
coxph_0 <- coxph(Surv(d.time, death==1) ~ 1, data = mydata)
r.martingale <- residuals(coxph_0, type="martingale")
```

#### For `age`


```{r}
# Modèle linéaire simple
age_linear <- coxph(Surv(d.time, death == 1) ~ age, data = mydata)

# Logarithme
mydata$logage <- as.vector(log(mydata$age))
mydata$logage <- as.numeric(scale(mydata$logage, center = TRUE, scale = FALSE))
age_log <- coxph(Surv(d.time, death == 1) ~ logage, data = mydata)

# Terme quadratique
mydata$agecarre <- mydata$age + mydata$age^2
fit2 <- coxph(Surv(d.time, death == 1) ~  agecarre, data = mydata)

# Racine carrée
mydata$agesqrt <- sqrt(mydata$age)
age_sqrt <- coxph(Surv(d.time, death == 1) ~ agesqrt, data = mydata)

# Inverse
mydata$ageinv <- 1 / mydata$age
age_inv <- coxph(Surv(d.time, death == 1) ~ ageinv, data = mydata)

# Spline naturelle (3 degrés de liberté)
age_spline <- coxph(Surv(d.time, death == 1) ~ ns(age, df = 3), data = mydata)

# Comparaison des AIC
AIC(age_linear, age_log, fit2, age_sqrt, age_inv, age_spline)
```





```{r}
# Graphique 1 : Martingale vs age
plot(r.martingale ~ mydata$age,
     col = "gray", pch = 19, xlab = "Age", ylab = "Martingale Residuals of Null Cox Model",
     main = "Martingale residuals vs Age")
smoothSEcurve(r.martingale, mydata$age)

```


```{r,}
# Graphique 2 : Martingale vs 1/age (age inverse)
plot(r.martingale ~ mydata$logage,
     col = "gray", pch = 19, xlab = "log(Age)", ylab = "Martingale Residuals of Null Cox Model", main = "Martingale residuals vs log(Age)")
smoothSEcurve(r.martingale, mydata$logage)

```



The analysis of Martingale residuals suggests an approximately linear effect of log-age on the log-hazard, justifying its inclusion as a continuous covariate in the model.









### For `resp`


```{r}
# Modèle linéaire simple
resp_linear <- coxph(Surv(d.time, death == 1) ~ resp, data = mydata)

# Logarithme
resp_log <- coxph(Surv(d.time, death == 1) ~ log(resp), data = mydata)

# Terme quadratique
mydata$respcarre <- mydata$resp + mydata$resp^2
fit2 <- coxph(Surv(d.time, death == 1) ~ respcarre, data = mydata)

# Racine carrée
mydata$respsqrt <- sqrt(mydata$resp)
resp_sqrt <- coxph(Surv(d.time, death == 1) ~ respsqrt, data = mydata)

# Inverse
mydata$respinv <- 1 / mydata$resp
resp_inv <- coxph(Surv(d.time, death == 1) ~ respinv, data = mydata)

# Spline naturelle (3 degrés de liberté)
resp_spline <- coxph(Surv(d.time, death == 1) ~ ns(resp, df = 3), data = mydata)

# Comparaison des AIC
AIC(resp_linear, resp_log, fit2, resp_sqrt, resp_inv, resp_spline)
```




### For `sod`

```{r}
# Modèle linéaire simple
sod_linear <- coxph(Surv(d.time, death == 1) ~ sod, data = mydata)

# Logarithme
sod_log <- coxph(Surv(d.time, death == 1) ~ log(sod), data = mydata)

# Terme quadratique
mydata$sodcarre <- mydata$sod  + mydata$sod^2
fit2 <- coxph(Surv(d.time, death == 1) ~  sodcarre, data = mydata)

# Racine carrée
mydata$sodsqrt <- sqrt(mydata$sod)
sod_sqrt <- coxph(Surv(d.time, death == 1) ~ sodsqrt, data = mydata)

# Inverse
mydata$sodinv <- 1 / mydata$sod
sod_inv <- coxph(Surv(d.time, death == 1) ~ sodinv, data = mydata)

# Spline naturelle (3 degrés de liberté)
sod_spline <- coxph(Surv(d.time, death == 1) ~ ns(sod, df = 3), data = mydata)

# Comparaison des AIC
AIC(sod_linear, sod_log, fit2, sod_sqrt, sod_inv, sod_spline)
```







## Consideration of the linearity assumption

* `age`: : logarithme

* `sod`: linéaire

* `resp` : linéaire







## Assessment of the Cox proportional hazards assumption

### Graphical approaches using log-log survival curves for categorical variables






```{r}
log_log_sex <- survfit(Surv(d.time, death==1) ~ sex, data = mydata)
plot(log_log_sex, fun = "cloglog", col = 1:2, xlab = "years", ylab = "log-log(Survival)")
title("log-log plot for sex (KM curve)")
legend("topleft", legend = levels(mydata$sex), col = 1:2, lty = 1)

```


```{r}
log_log_income <- survfit(Surv(d.time, death == 1) ~ income, data = mydata)

plot(log_log_income, fun = "cloglog", 
     col = 1:length(unique(mydata$income)), 
     xlab = "Time (in quarters, 3-month periods)", ylab = "log-log(Survival)")

title("Log-log plot for income (KM curve)")

legend("bottomright", legend = levels(mydata$income), 
       col = 1:length(unique(mydata$income)), lty = 1)

```

The proportional hazards (PH) assumption appears to hold for the variable `income`.

## Checking the Proportional Hazards Assumption with the `cox.zph` Function

The verification is performed using the `cox.zph` function from the `survival` package.

Transformations applied to continuous variables:

- `age`: logarithmic transformation (`log(age)`)
- `sod`: inverse transformation (`1/sod`)
- `resp`: quadratic transformation (`resp + resp^2`)






##   Proportionality (PH) and Linearity Assumptions


```{r}

PH_data_clean <- coxph(Surv(d.time, death==1) ~ age + sex +   income + sod+   resp  , data = mydata)
```


```{r}
reszphkm <- cox.zph(PH_data_clean)
reszphkm
```

## Assessment of Proportional Hazards (PH) and Linearity Assumptions

- **age**: strong violation of the PH assumption; include a time interaction (e.g., `tt(age)`).
- **sex**: significant violation; consider stratifying the model by `sex`.
- **income**: no violation detected.
- **resp**: slight violation; may require further evaluation.
- **sod**: no violation detected.
- **GLOBAL test**: overall PH assumption is violated.

### Linearity Assumption (based on martingale residuals)

- **age**: log-transformation applied.
- **sod**: linear form appropriate.
- **resp**: linear form appropriate.




## Study data


```{r}
sampledata <- mydata[, c("d.time", "death","income","sex","age", "logage", "sod","resp") ]
```


```{r}
summary(sampledata)
```



### Proportion of the SUPPORT Dataset Included in the Analysis

```{r}
prop_use_support <- (nrow(sampledata)/nrow(support2))*100
prop_use_support
```

  

## Realistic Data Simulation





```{r}
set.seed(123)  # pour la reproductibilité

# Liste de 1000 jeux de données simulés
nsim =1000
sampledata <- lapply(1:nsim, function(i) {
  sampledata[sample(1:nrow(sampledata), size = 1000, replace = FALSE), ]
})
```






### Generation of Missing Data Under MAR

The predictive variables for the missingness mechanism in the real dataset are: `age`, `sod`, and `death`.


```{r}
simulate_mar <- function(data, mar_var = "income", prop = 0.3, seed = 123) {
  set.seed(seed)
  
  # 1. Vérification et sauvegarde des niveaux
  if (!is.factor(data[[mar_var]])) stop("La variable cible doit être un facteur.")
  target_levels <- levels(data[[mar_var]])
  
  # 2. Variables explicatives 
  vars <- c( mar_var, "death",   "age",  "sod")
  
  # 3. Transformation en dummies (sans intercept)
  X <- model.matrix(~ ., data = data[, vars])[, -1]
  X <- as.data.frame(X)
  
  # 4. Identifier les colonnes dummies associées à la variable cible
  target_cols_idx <- grep(paste0("^", mar_var), names(X))
  if (length(target_cols_idx) == 0) stop("Aucune variable dummy trouvée pour ", mar_var)
  
  # 5. Construire le pattern MAR : 0 = à amputer, 1 = à garder
  pattern <- matrix(1, nrow = 1, ncol = ncol(X))
  pattern[1, target_cols_idx] <- 0
  colnames(pattern) <- colnames(X)
  
  # 6. Construire les poids pour MAR
  weights <- matrix(0, nrow = 1, ncol = ncol(X))
  other_cols_idx <- setdiff(seq_len(ncol(X)), target_cols_idx)
  weights[1, other_cols_idx] <- runif(length(other_cols_idx))
  colnames(weights) <- colnames(X)
  
  # 7. Appliquer amputation
  amp <- mice::ampute(
    data = X,
    prop = prop,
    patterns = pattern,
    freq = 1,
    weights = weights,
    mech = "MAR"
  )
  
  # 8. Reconstruire la variable cible
  target_cols_names <- names(X)[target_cols_idx]
  recovered <- apply(amp$amp[, target_cols_names], 1, function(row) {
    if (all(is.na(row))) return(NA)
    ref <- target_levels[1]
    idx <- which(row == 1)
    if (length(idx) == 0) return(ref)
    return(target_levels[idx + 1])
  })
  
  # 9. Indicateur de complétude
  R <- ifelse(is.na(recovered), 0, 1)
  
  # 10. Mettre à jour le jeu de données
  new_data <- data
  new_data[[paste0(mar_var, ".mis")]] <- factor(recovered, levels = target_levels)
  new_data[["R"]] <- R
  
  return(new_data)
}

```




```{r}
sampledata <- lapply(sampledata, function(data) {
  data <- simulate_mar(data = data)
  return(data)
})
```


#### Fonction pour proportions moyennes des observations censurées et manquantes.

```{r}
prop <- function(data, nsim, variable) {
  mat <- matrix(NA, ncol = 2, nrow = nsim, dimnames = list(NULL, c("0", "1")))
  for (s in 1:nsim) {
    mat[s, ] <- prop.table(table(factor(data[[s]][, variable], levels = c(0, 1))))
  }
  return(mat)
}
```

#### Average Proportion of Censored Observations

```{r}
prop_delta <- colMeans(prop(sampledata, nsim,"death"))*100
prop_delta
```

#### Average Proportion of Missing Observations


```{r}
prop_NA <- colMeans(prop(sampledata, nsim,"R"))*100
prop_NA
```




## Function to Add the Nelson-Aalen Cumulative Hazard

```{r}
addcumhaz <- function(data, time_var = "time", event_var = "delta") {
  # Vérification de la présence des colonnes spécifiées
  if (!all(c(time_var, event_var) %in% colnames(data))) {
    stop("Les colonnes spécifiées doivent être présentes dans les données.")
  }
  
  # Construction dynamique de l'objet Surv
  surv_obj <- survival::Surv(time = data[[time_var]], event = data[[event_var]] == 1)
  
  # Ajustement du modèle de survie
  fit <- survival::survfit(surv_obj ~ 1, data = data, type = "fh")
  
  # Initialisation de la variable cumhaz à NA
  data$cumhaz <- NA
  
  # Appariement des temps
  time_values <- data[[time_var]]
  time_indices <- match(time_values, fit$time)
  
  # Remplissage de cumhaz
  data$cumhaz[!is.na(time_indices)] <- fit$cumhaz[time_indices[!is.na(time_indices)]]
  
  return(data)
}

```


```{r}
sampledata <- lapply(sampledata, function(df) addcumhaz(df, time_var = "d.time", event_var = "death"))
```




## Full Data (Without Missing Values): Estimation of Beta Parameters

We implicitly assume that the final analysis model is correctly specified and that the variability due to simulation is negligible compared to the impact of the imputation methods.
 


```{r}
PACKAGE <- function(package){
  for(p in package){
    library(p, character.only = TRUE)
  }
}
```

```{r}
cl <- makeCluster(detectCores() - 1)
clusterExport(cl, c("sampledata"))
invisible(clusterCall(cl, PACKAGE, c("survival")))

Full.mod <- parLapply(cl, sampledata, function(data) {
  coxph(
formula = Surv(d.time, death == 1) ~ income + resp + sod + tt(logage) + strata(sex),tt = function(x, t, ...) {x * t},data = data)})

stopCluster(cl)
```


```{r}
cl <- makeCluster(detectCores() - 1)
clusterExport(cl, c("Full.mod"))
Full.est <- parLapply(cl, Full.mod, function(model) {
  summ <- summary(model)
  coef <- summ$coefficients[, "coef"]
  se <- summ$coefficients[, "se(coef)"]
  est_df <- data.frame(
    Estimate = coef,
    CI_low = coef - qnorm(0.975) * se,
    CI_up = coef + qnorm(0.975) * se
  )
  return(est_df)
})
stopCluster(cl)
```




```{r}
estimate_list <- lapply(Full.est, function(df) df$Estimate)
estimate_matrix <- do.call(rbind, estimate_list)
beta <- colMeans(estimate_matrix)
beta
```

## Utility Functions for the Simulation Study




```{r}
fun_var <- function(esti_ech, esti_mean){
  return((esti_ech - esti_mean)^2)
}

fun_coverage <- function(value, CI.low, CI.upper){
  ifelse(CI.low <= value & CI.upper >= value,1,0)
}
```


```{r}
full_mcar_mar <- function(True, hat_estimate, nsim){
  estime_by_sim <- var_by_sim <-  Cover_by_sim <- CI_width <- data.frame(matrix(NA, nrow = nrow(hat_estimate[[1]]),ncol = nsim))
  for(s in 1:nsim){
    estime_by_sim[,s] <- hat_estimate[[s]]["Estimate"]
    var_by_sim[,s] <- fun_var(esti_ech = hat_estimate[[s]][,"Estimate"], esti_mean = rowMeans(sapply(hat_estimate, function(x) x[,"Estimate"])) )
    Cover_by_sim[,s] <- fun_coverage(value = True, CI.low = hat_estimate[[s]]["CI_low"], CI.upper = hat_estimate[[s]]["CI_up"])
  }
  
  out_result <- data.frame("True" = True,
                           "Estimate" = rowMeans(estime_by_sim),
                           "Emp_sd" = sqrt(rowSums(var_by_sim)/(nsim -1)),
                           "CI_low" = rowMeans(estime_by_sim) - qnorm(0.975)*sqrt(rowSums(var_by_sim)/(nsim -1)),
                           "CI_up" = rowMeans(estime_by_sim) + qnorm(0.975)*sqrt(rowSums(var_by_sim)/(nsim -1)),
                           "CI_width" =  2 * qnorm(0.975) * sqrt(rowSums(var_by_sim) / (nsim - 1)),
                           "Cover" = rowMeans(Cover_by_sim),
                           "Cover_low" = rowMeans(Cover_by_sim)-qnorm(0.975)*sqrt((rowMeans(Cover_by_sim)*(1-rowMeans(Cover_by_sim)))/nsim),
                           "Cover_up" = rowMeans(Cover_by_sim)+qnorm(0.975)*sqrt((rowMeans(Cover_by_sim)*(1-rowMeans(Cover_by_sim)))/nsim))
  rownames(out_result ) <- row.names(hat_estimate[[1]])
  return(out_result = out_result)
}

```

## Completes cases anlysis: (MCAR)





```{r}
cl <- makeCluster(detectCores() - 1)
clusterExport(cl, c("sampledata"))
invisible(clusterCall(cl, PACKAGE, c("survival")))
MCAR.mod <- parLapply(cl, sampledata, function(data) {
  coxph(
  formula = Surv(d.time, death == 1) ~ income.mis +  resp + sod + tt(logage) + strata(sex),tt = function(x, t, ...) {x * t},data = data)
})
stopCluster(cl) 

```


```{r}
cl <- makeCluster(detectCores() - 1)
clusterExport(cl, c("MCAR.mod"))
MCAR.est <- parLapply(cl, MCAR.mod, function(model) {
  summ <- summary(model)
  coef <- summ$coefficients[, "coef"]
  se <- summ$coefficients[, "se(coef)"]
  est_df <- data.frame(
    Estimate = coef,
    CI_low = coef - qnorm(0.975) * se,
    CI_up = coef + qnorm(0.975) * se
  )
  return(est_df)
})
stopCluster(cl) 
```



```{r}
estimcar <- full_mcar_mar(True = beta,nsim =nsim, hat_estimate = MCAR.est)
estimcar
```



## Semi-parametric Approach: Inverse Probability Weighting (MAR)

### Trade-off Parameter


```{r}
# kappa = 1 
# kappa = 0.95 pas encore
# kappa = 0.9 pas encore
# kappa = 0.8 pas encore
# kappa = 0.7 pas encore
# kappa = 0.5 
 kappa = 0.4
# kappa = 0.3 
# kappa = 0.2
# kappa = 0 
```


```{r}
set.seed(312)
sampledata <- lapply(1:nsim, function(s) {
  work.model <- glm(R ~  death + age  +sod, data = sampledata[[s]], family = binomial)
  predicted <-  pmax(pmin(predict(work.model, type = "response"), 0.99), 0.01)
  sampledata[[s]]$w <- ifelse(
    sampledata[[s]]$R == 1,
    1 / predicted, 
    kappa*1 + (1-kappa)*(1 / (1-predicted))
  )
  
  return(sampledata[[s]])
})

```


```{r}
cl <- makeCluster(detectCores() - 1)
clusterExport(cl, c("sampledata"))
invisible(clusterCall(cl, function() library(survival)))

iwp.mod <- parLapply(cl, sampledata, function(data) {
  coxph(
  formula = Surv(d.time, death == 1) ~ income.mis +  resp + sod + tt(logage) + strata(sex),tt = function(x, t, ...) {x * t}, weights = w, data = data, robust = TRUE)
})
stopCluster(cl)

```


```{r}
cl <- makeCluster(detectCores() - 1)
clusterExport(cl, c("iwp.mod"))
iwp.est <- parLapply(cl, iwp.mod, function(model) {
  summ <- summary(model)
  coef <- summ$coefficients[, "coef"]
  se <- summ$coefficients[, "robust se"]
  est_df <- data.frame(
    Estimate = coef,
    CI_low = coef - qnorm(0.975) * se,
    CI_up = coef + qnorm(0.975) * se
  )
  return(est_df)
})

stopCluster(cl)
```


```{r}
estimar_iwp <- full_mcar_mar(True = beta,nsim = nsim, hat_estimate = iwp.est)
estimar_iwp
```


## Parametric Multiple Imputation (MAR)

## Parametric Imputation with the `mice` Package (MAR)

### Number of Imputations


```{r}
M = 10
```


```{r}

cl <- makeCluster(detectCores())
clusterExport(cl, c("sampledata", "M")) 
invisible(clusterCall(cl, PACKAGE, c("mice")))
mice_P_data <- parLapply(cl, 1:nsim, function(s) {
  mice(
    data= sampledata[[s]][,c("cumhaz", "death" ,"income.mis","sex", "age",  "logage","resp",  "sod" )],  
    m = M,         
    maxit = 10,      
    method = c("norm","logreg", "polyreg","logreg", "norm", "norm","norm", "norm"),
    print = FALSE,
    seed = 10000
  )
})

```



```{r}
mice_P_data <- lapply(1:nsim, function(s) {
  # Créer une liste de jeux de données combinés pour chaque imputation
  combined_data <- lapply(1:M, function(m) {
    cbind("d.time"= sampledata[[s]]$d.time, mice::complete(mice_P_data[[s]], m))
  })
  
  # Convertir la liste de données en un objet mids
  mitml_object <- mitml::as.mitml.list(combined_data)
  
  return(mitml_object)
})

```

```{r}
combine_MI <- function(manyresult) {
  # Vérification
  if (!all(sapply(manyresult, inherits, what = "coxph"))) {
    stop("Tous les éléments de 'manyresult' doivent être des objets 'coxph'.")
  }
  
  estimates <- list()
  variances <- list()
  
  for (i in seq_along(manyresult)) {
    mod.sum <- summary(manyresult[[i]])
    
    # Détecter si les erreurs sont robustes
    se_col <- if ("robust se" %in% colnames(mod.sum$coefficients)) {
      "robust se"
    } else {
      "se(coef)"
    }
    
    estimates[[i]] <- mod.sum$coefficients[, "coef"]
    variances[[i]] <- mod.sum$coefficients[, se_col]^2
  }
  
  estimates_mat <- do.call(rbind, estimates)
  variances_mat <- do.call(rbind, variances)
  
  m <- length(manyresult)
  
  Q_bar <- colMeans(estimates_mat)
  U_bar <- colMeans(variances_mat)
  B <- apply(estimates_mat, 2, var) * (m / (m - 1))
  T <- U_bar + (1 + 1 / m) * B
  se <- sqrt(T)
  
  # Degrés de liberté (formule classique de Rubin, 1987)
  df <- (m - 1) * (T / B)^2
  
  # Intervalles de confiance
  CI_low <- Q_bar - qt(0.975, df) * se
  CI_up <- Q_bar + qt(0.975, df) * se
  
  # p-value (z-test approx)
  z <- Q_bar / se
  p_value <- 2 * (1 - pnorm(abs(z)))
  
  result <- data.frame(
    "coef" = Q_bar,
    "lower.95" = CI_low,
    "upper.95" = CI_up,
    check.names = FALSE,
    row.names = rownames(estimates_mat)
  )
  return(result)
}

```



```{r}
compute_mar <- function(data){
  mar.model <- with(data, coxph(
  formula = Surv(d.time, death == 1) ~ income.mis +  resp + sod + tt(logage) + strata(sex),tt = function(x, t, ...) {x * t}))
  mar.est <- combine_MI(mar.model)
  colnames(mar.est) <- c("Estimate",  "CI_low", "CI_up")
  return(mar.est)
}
```



```{r}

cl <- makeCluster(detectCores())
clusterExport(cl, c("mice_P_data","compute_mar","combine_MI"))
invisible(clusterCall(cl, PACKAGE, c("survival","mice","mitml")))
tout_mice.est <- parLapply(cl,  1:nsim, function(s){
  compute_mar(data = mice_P_data[[s]])
})
stopCluster(cl)

```


```{r}
estimar_P_mice <- full_mcar_mar(True = beta,nsim = nsim, hat_estimate = tout_mice.est)
estimar_P_mice
```

## Nonparametric Imputation: Random Forest (MAR)



```{r}
cl <- makeCluster(detectCores())
clusterExport(cl, c("sampledata", "M")) 
invisible(clusterCall(cl, PACKAGE, c("mice","ranger")))
mice.rf.data <- parLapply(cl, 1:nsim, function(s) {
  mice(
    data= sampledata[[s]][,c("cumhaz", "death" ,"income.mis","sex", "age",  "logage","resp",  "sod" )],  
    m = M,         
    maxit = 10,      
    method = c("rf","rf", "rf","rf","rf","rf","rf", "rf"), 
    print = FALSE,
    seed = 10000
  )
})

stopCluster(cl)
```


```{r}
mice.rf.data <- lapply(1:nsim, function(s) {
  # Créer une liste de jeux de données combinés pour chaque imputation
  combined_data <- lapply(1:M, function(m) {
    cbind("d.time"= sampledata[[s]]$d.time, mice::complete(mice.rf.data[[s]], m))
  })
  
  # Convertir la liste de données en un objet mids
  mitml_object <- mitml::as.mitml.list(combined_data)
  
  return(mitml_object)
})
```



```{r}
cl <- makeCluster(detectCores())
clusterExport(cl, c("mice.rf.data","compute_mar","combine_MI"))
invisible(clusterCall(cl, PACKAGE, c("survival","mice","ranger")))
tout_mice.rf.est <- parLapply(cl,  1:nsim, function(s){
  compute_mar(data = mice.rf.data[[s]])
})
stopCluster(cl)

```

```{r}
estimar_mice_RF_NP <- full_mcar_mar(True = beta,nsim = nsim, hat_estimate = tout_mice.rf.est)

estimar_mice_RF_NP
```


# Hybrid Methods

## Hybrid 1: Parametric MI and Nonparametric MI (MAR)



```{r}
P_NP_data <- lapply(1:nsim, function(s) {
  temp_data <- vector("list", M)
  for (i in 1:(M/2)) {
    temp_data[[i]] <- mice_P_data[[s]][[i]]
    temp_data[[i + (M/2)]] <- mice.rf.data[[s]][[i]]
  }
  temp_data <- mitml::as.mitml.list(temp_data)
  temp_data
})
```




```{r}
cl <- makeCluster(detectCores())
clusterExport(cl, c("P_NP_data","compute_mar","combine_MI"))
invisible(clusterCall(cl, PACKAGE, c("survival","mice", "mitml","ranger")))
tout_P_NP.est <- parLapply(cl,  1: nsim, function(s){
  compute_mar(data = P_NP_data[[s]])
})
stopCluster(cl)

```


```{r}
estimar_mice_P_NP <- full_mcar_mar(True = beta,nsim = nsim, hat_estimate = tout_P_NP.est)
estimar_mice_P_NP
```





## Hybrid 2: Parametric MI and IPW (MAR)




```{r}
MI.P_IWP_data <- lapply(1:nsim, function(s) {
  imputation <- lapply(1:M, function(m) {
    cbind(mice_P_data[[s]][[m]],
          sampledata[[s]][, c("R", "w")]
    )
  })
})

```




```{r}
compute_MI_IWP <- function(data_list) {
  # Initialiser des vecteurs pour stocker les estimations, les variances robustes et les IC
  estimates <- list()
  robust_variances <- list()
  
  # Parcourir chaque jeu d'imputation
  for (i in seq_along(data_list)) {
    # Ajuster le modèle de Cox pour chaque jeu de données imputé
    fit <- coxph(Surv(d.time, death == "1") ~ income.mis +  resp + sod + tt(logage) + strata(sex),tt = function(x, t, ...) {x * t}, data = data_list[[i]], weights = data_list[[i]]$w,robust = TRUE)
    
    # Stocker les estimations
    estimates[[i]] <- coef(fit)  # Coefficients estimés
    
    # Calculer et stocker les variances robustes
    robust_variances[[i]] <- diag(vcov(fit, robust = TRUE))  # Variances robustes des coefficients estimés
  }
  
  # Convertir les résultats en matrices pour faciliter les calculs
  estimates_mat <- do.call(rbind, estimates)
  robust_variances_mat <- do.call(rbind, robust_variances)
  
  # Nombre d'imputations
  m <- length(data_list)
  
  # Combiner les estimations et les variances avec la règle de Rubin
  Q_bar <- colMeans(estimates_mat)  # Moyenne des estimations
  U_bar <- colMeans(robust_variances_mat)  # Variance intra-imputation (robuste)
  B <- apply(estimates_mat, 2, var)*(m / (m - 1))  # Variance inter-imputation
  T <- U_bar + (1 + 1/m) * B  # Variance totale combinée
  
  # df: degrés de liberté de Rubin
  df <- (m - 1)*(1 + U_bar/B)^2
  
  # Calcul des erreurs standards et des IC combinés
  CI_low_combined <- Q_bar - qt(0.975, df = df) * sqrt(T)
  CI_up_combined <- Q_bar + qt(0.975, df = df) * sqrt(T)
  
  # Résultat final sous forme de data.frame
  mar.est <- data.frame(
    Estimate = Q_bar,
    CI_low = CI_low_combined,
    CI_up = CI_up_combined
  )
  return(mar.est)
}
```




```{r}
cl <- makeCluster(detectCores())
clusterExport(cl, c("MI.P_IWP_data","compute_MI_IWP"))
invisible(clusterCall(cl, PACKAGE, c("survival","mice","mitml")))
tout_miceP_iwp.est <- parLapply(cl,  1:nsim, function(s){
  compute_MI_IWP(data = MI.P_IWP_data[[s]])
})
stopCluster(cl)
```





```{r}
estimar_mice_P_iwp <- full_mcar_mar(True = beta,nsim = nsim, hat_estimate = tout_miceP_iwp.est)
estimar_mice_P_iwp
```









## Hybrid 3: Nonparametric MI and IPW (MAR)




```{r}
MI.NP_IWP_data <- lapply(1:nsim, function(s) {
  lapply(1:M, function(m) {
    cbind(mice.rf.data[[s]][[m]],
          sampledata[[s]][, c("R", "w")]
    )
  })
})

```





```{r}
cl <- makeCluster(detectCores())
clusterExport(cl, c("MI.NP_IWP_data","compute_MI_IWP"))
invisible(clusterCall(cl, PACKAGE, c("survival","mice","mitml","ranger")))
tout_miceNP_iwp.est <- parLapply(cl,  1:nsim, function(s){
  compute_MI_IWP(data = MI.NP_IWP_data[[s]])
})
stopCluster(cl)
```


```{r}
estimar_mice_NP_iwp <- full_mcar_mar(True = beta,nsim = nsim, hat_estimate = tout_miceNP_iwp.est)
estimar_mice_NP_iwp

```




## Hybrid 4: Parametric MI, Nonparametric MI, and IPW (MAR)



```{r}
P_NP_IWP_data <- lapply(1:nsim, function(s){
  lapply(1:M, function(m){
    cbind(P_NP_data[[s]][[m]],
          sampledata[[s]][, c("R", "w")])
  })
})

```




```{r}
cl <- makeCluster(detectCores())
clusterExport(cl, c("P_NP_IWP_data","compute_MI_IWP"))
invisible(clusterCall(cl, PACKAGE, c("survival","mice","mitml","ranger")))
tout_mice_P_NP_iwp.est <- parLapply(cl,  1:nsim, function(s){
  compute_MI_IWP(data = P_NP_IWP_data[[s]])
})
stopCluster(cl)
```





```{r}
estimar_mice_P_NP_iwp <- full_mcar_mar(True = beta,nsim = nsim, hat_estimate = tout_mice_P_NP_iwp.est)
estimar_mice_P_NP_iwp
```




# Results


```{r}
bias_relative <- function(value,hat_estimate){
  return(((hat_estimate - value)/value)*100)
}


biais_absolu <- function(value, hat_estimate) {
  return(abs(hat_estimate - value))
}

```




## The Estimates


```{r}
all_estimate <- data.frame(True = beta,
                           CC = estimcar[,"Estimate"],
                           Iwp = estimar_iwp[,"Estimate"],
                           Mice.P = estimar_P_mice[,"Estimate"],
                           RF.NP = estimar_mice_RF_NP[,"Estimate"],
                           Hybrid1 = estimar_mice_P_NP[,"Estimate"],
                           Hybrid2 = estimar_mice_P_iwp[,"Estimate"],
                           Hybrid3 = estimar_mice_NP_iwp[,"Estimate"],
                           Hybrid4 = estimar_mice_P_NP_iwp[,"Estimate"])
rownames(all_estimate) <- rownames(Full.est[[1]])

knitr::kable(round(all_estimate, 4))
```




## Absolute Bias

```{r}
ab_biais <- data.frame( CC = biais_absolu(value = beta,hat_estimate = estimcar[,"Estimate"]),
                        Iwp = biais_absolu(value = beta,hat_estimate = estimar_iwp[,"Estimate"]),
                        Mice.P = biais_absolu(value = beta,hat_estimate = estimar_P_mice[,"Estimate"]),
                        RF.NP = biais_absolu(value = beta,hat_estimate = estimar_mice_RF_NP[,"Estimate"]),
                        Hybrid1 = biais_absolu(value = beta,hat_estimate = estimar_mice_P_NP[,"Estimate"]),
                        Hybrid2 = biais_absolu(value = beta,hat_estimate = estimar_mice_P_iwp[,"Estimate"]),
                        Hybrid3 = biais_absolu(value = beta,hat_estimate = estimar_mice_NP_iwp[,"Estimate"]),
                        Hybrid4 = biais_absolu(value = beta,hat_estimate = estimar_mice_P_NP_iwp[,"Estimate"]))


rownames(ab_biais) <- rownames(Full.est[[1]])
knitr::kable(round(ab_biais,5))
```



## Relative Bias (in Percentage)

```{r}
all_bias <- data.frame( CC = bias_relative(value = beta,hat_estimate = estimcar[,"Estimate"]),
                       Iwp = bias_relative(value = beta,hat_estimate = estimar_iwp[,"Estimate"]),
                       Mice.P = bias_relative(value = beta,hat_estimate = estimar_P_mice[,"Estimate"]),
                       RF.NP = bias_relative(value = beta,hat_estimate = estimar_mice_RF_NP[,"Estimate"]),
                       Hybrid1 = bias_relative(value = beta,hat_estimate = estimar_mice_P_NP[,"Estimate"]),
                       Hybrid2 = bias_relative(value = beta,hat_estimate = estimar_mice_P_iwp[,"Estimate"]),
                       Hybrid3 = bias_relative(value = beta,hat_estimate = estimar_mice_NP_iwp[,"Estimate"]),
                       Hybrid4 = bias_relative(value = beta,hat_estimate = estimar_mice_P_NP_iwp[,"Estimate"]))


rownames(all_bias) <- rownames(Full.est[[1]])
knitr::kable(round(all_bias,3))
```





## standard deviation

```{r}
all_sd <- data.frame(
                     CC = estimcar[,"Emp_sd"],
                     Iwp = estimar_iwp[,"Emp_sd"],
                     Mice.P = estimar_P_mice[,"Emp_sd"],
                     RF.NP = estimar_mice_RF_NP[,"Emp_sd"],
                     Hybrid1 = estimar_mice_P_NP[,"Emp_sd"],
                     Hybrid2 = estimar_mice_P_iwp[,"Emp_sd"],
                     Hybrid3 = estimar_mice_NP_iwp[,"Emp_sd"],
                     Hybrid4 = estimar_mice_P_NP_iwp[,"Emp_sd"])


rownames(all_sd) <- rownames(Full.est[[1]])
knitr::kable(round(all_sd,3))
```




## Coverage

```{r}
all_coverage <- data.frame(
                           CC = estimcar[,"Cover"],
                           Iwp = estimar_iwp[,"Cover"],
                           Mice.P = estimar_P_mice[,"Cover"],
                           RF.NP = estimar_mice_RF_NP[,"Cover"],
                           Hybrid1 = estimar_mice_P_NP[,"Cover"],
                           Hybrid2 = estimar_mice_P_iwp[,"Cover"],
                           Hybrid3 = estimar_mice_NP_iwp[,"Cover"],
                           Hybrid4 = estimar_mice_P_NP_iwp[,"Cover"])


rownames(all_coverage) <- rownames(Full.est[[1]])
knitr::kable(round(all_coverage*100,5))
```




## Confidence Interval Widths

```{r}
all_CI_width <- data.frame(
                           CC = estimcar[,"CI_width"],
                           Iwp = estimar_iwp[,"CI_width"],
                           Mice.P = estimar_P_mice[,"CI_width"],
                           RF.NP = estimar_mice_RF_NP[,"CI_width"],
                           Hybrid1 = estimar_mice_P_NP[,"CI_width"],
                           Hybrid2= estimar_mice_P_iwp[,"CI_width"],
                           Hybrid3= estimar_mice_NP_iwp[,"CI_width"],
                           Hybrid4 = estimar_mice_P_NP_iwp[,"CI_width"])



rownames(all_CI_width) <- rownames(Full.est[[1]])
knitr::kable(round(all_CI_width,3))
```


```{r}

tf <- Sys.time()
code_time <- tf - ti
code_time



# sink()
```

