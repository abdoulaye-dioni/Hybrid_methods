

########### Méthodes hybrides: Simulation #############

# sink("scenario1.txt")
  
```{r} 
ti <- Sys.time()

## Packages 

library(survival)
library(parallel)
library(mice)
library(mitml)
library(dplyr)
library(ranger)
```

# Fonction pour simuler les données de survie


```{r}

simulate_Cox_weibull <- function(n, nu, eta, beta, lambda) {
  X3 <- rnorm(n, 0, 1)
  X2 <- factor(rbinom(n, size = 1, prob = 0.4))
  eta_X1 <- model.matrix(as.formula(formula_X1), data.frame(X2 = X2, X3 = X3))[,-1] %*% as.matrix(para_X1)
  prob_X1 <-  t(apply(eta_X1, 1, function(x) exp(x - max(x)) / sum(exp(x - max(x)))))
  X1 <-factor(apply(prob_X1, 1, function(p) sample(1:length(p), 1, prob = p)))
  linear_predictor <- model.matrix(~ X1 + X2 + X3)[, -1]%*% beta
  T_e <- (-log(runif(n)) / (nu * exp(linear_predictor)))^(1 / eta)
  T_c <- rexp(n, rate = lambda)
  delta <- as.factor(ifelse(T_e <= T_c, 1, 0))  # 1 = événement, 0 = censuré
  time <- round(pmin(T_e, T_c),2)
  return(data.frame(id = seq_len(n), time = time, delta = delta, X1 = X1, X2 = X2, X3 = X3))
}

```


## Paramètres de la fonction de  simulation

```{r}
set.seed(123)
n=1000 # Taille de l'échantillon
nu = 1.2 # Paramètre de forme de la distribution de weibull
eta =10 #  Paramètre d'échelle de la distribution de weibull
beta= c(-log(2),log(3),-log(1.5),log(2))

formula_X1 <- "~ X2 + X3"
para_X1 <- matrix(c(rep(1,2), rep(1,2),rep(1,2) ),ncol = 3)

# Paramètre lambda pour introduire la censure dans les données

lambda = 0.3 # scénario 1
#lambda = 0.5 # scénario 2
#lambda = 0.7 # scénario 3 # Non présenter dans le papier
#lambda = 0.9 # scénario 4 # Non présenter dans le papier
```



## Nombre de simulation

```{r}
nsim = 1000
```


## Données simulées

```{r}
datas <- lapply(1:nsim, function(s) {
  data <- simulate_Cox_weibull(n=n,nu =nu, eta = eta,beta = beta,lambda = lambda)
  return(data)
})

```

## Fonction pour générer les valeurs manquantes sous MAR

```{r}
simulate_mar <- function(data,  alpha, mar_var) {
  prob_R <- plogis(model.matrix(~ time + delta +  X2 + X3, data)[, -1] %*% alpha) 
  data$R <- as.factor(rbinom(nrow(data), 1, prob_R)) # Variable indicatrice des données manquantes
  data[[paste0(mar_var, ".mis")]] <- as.factor(ifelse(data$R == 1, data[[mar_var]], NA))
  return(data)
}
```


## Paramètres  de la fonction de simulation des données manquantes

```{r}
set.seed(450)

alpha = c(-1,2.5,1,1) # Scénario 1
#alpha = c(-0.5,1.5,0.5,1) # Scénario 2
#alpha = c(0.5,-0.5,0.5,2) # Scénario 3 # Non présenter dans le papier
#alpha = c(-1,1,-0.5,1.5) # Scénario 4 # Non présenter dans le papier
```



## Mise à jour des données simulées

```{r}
datas <- lapply(datas, function(data) {
  data <- simulate_mar(data = data,  alpha = alpha, mar_var = "X1")
  return(data)
})

```

# Fonction pour proportions moyennes des observations censurées et manquantes.


```{r}
prop <- function(data, nsim, variable) {
  mat <- matrix(NA, ncol = 2, nrow = nsim, dimnames = list(NULL, c("0", "1")))
  for (s in 1:nsim) {
    mat[s, ] <- prop.table(table(factor(data[[s]][, variable], levels = c(0, 1))))
  }
  return(mat)
}

```


## Proportion moyenne des observations censurées


```{r}
prop_delta <- colMeans(prop(datas, nsim,"delta"))*100
prop_delta
```


## Proportion moyenne des observations manquantes

```{r}
prop_NA <- colMeans(prop(datas, nsim,"R"))*100
prop_NA
```



# Fonction pour ajouter le Nelson-Aalen cumulative hazard

```{r}
addcumhaz <- function(data) {
  if (!all(c("time", "delta") %in% colnames(data))) {
    stop("Les colonnes 'time' et 'delta' doivent être présentes dans les données.")
  }
  fit <-  survival::survfit(survival::Surv(time, delta == 1) ~ 1, data = data, type = "fh")
  data$cumhaz <- NA
  time_indices <- match(data$time, fit$time)
  data$cumhaz[!is.na(time_indices)] <- fit$cumhaz[time_indices[!is.na(time_indices)]]
  
  return(data)
}
```

## Mise à jour des données simulées

```{r}
datas <- lapply(datas, addcumhaz)

```


## Fonctions pour charger des packages dans un calcul en parallèle

```{r}
PACKAGE <- function(package){
  for(p in package){
    library(p, character.only = TRUE)
  }
}
```



## Fonction pour le calcul de la variance et de la couverture des intervalles de confiance

```{r}
fun_var <- function(esti_ech, esti_mean){
  return((esti_ech - esti_mean)^2)
}

fun_coverage <- function(value, CI.low, CI.upper){
  ifelse(CI.low <= value & CI.upper >= value,1,0)
}
```



## Fonction  utile dans le cadre d'une simulation

```{r}
full_mcar_mar <- function(True, hat_estimate, nsim){
  estime_by_sim <- var_by_sim <-  Cover_by_sim <- CI_width <- data.frame(matrix(NA, nrow = nrow(hat_estimate[[1]]),ncol = nsim))
  for(s in 1:nsim){
    estime_by_sim[,s] <- hat_estimate[[s]]["Estimate"]
    var_by_sim[,s] <- fun_var(esti_ech = hat_estimate[[s]][,"Estimate"], esti_mean = rowMeans(sapply(hat_estimate, function(x) x[,"Estimate"])) )
    Cover_by_sim[,s] <- fun_coverage(value = True, CI.low = hat_estimate[[s]]["CI_low"], CI.upper = hat_estimate[[s]]["CI_up"])
  }
  
  out_result <- data.frame("True" = True,
                           "Estimate" = rowMeans(estime_by_sim),
                           "Emp_sd" = sqrt(rowSums(var_by_sim)/(nsim -1)),
                           "CI_low" = rowMeans(estime_by_sim) - qnorm(0.975)*sqrt(rowSums(var_by_sim)/(nsim -1)),
                           "CI_up" = rowMeans(estime_by_sim) + qnorm(0.975)*sqrt(rowSums(var_by_sim)/(nsim -1)),
                           "CI_width" =  2 * qnorm(0.975) * sqrt(rowSums(var_by_sim) / (nsim - 1)),
                           "Cover" = rowMeans(Cover_by_sim),
                           "Cover_low" = rowMeans(Cover_by_sim)-qnorm(0.975)*sqrt((rowMeans(Cover_by_sim)*(1-rowMeans(Cover_by_sim)))/nsim),
                           "Cover_up" = rowMeans(Cover_by_sim)+qnorm(0.975)*sqrt((rowMeans(Cover_by_sim)*(1-rowMeans(Cover_by_sim)))/nsim))
  rownames(out_result ) <- row.names(hat_estimate[[1]])
  return(out_result = out_result)
}

```


## Full data (Données simulées sans valeurs manquantes)


```{r}
cl <- makeCluster(detectCores())
clusterExport(cl, c("datas"))
invisible(clusterCall(cl, PACKAGE, c("survival")))

Full.mod <- parLapply(cl, datas, function(data) {
  coxph(Surv(time, delta=="1") ~ X1 + X2 +X3, data = data)
})

Full.est <- parLapply(cl, Full.mod, function(model) {
  coef <- model$coefficients
  conf_intervals <- confint(model)
  est_df <- data.frame(
    "Estimate" = coef,
    "CI_low" = conf_intervals[, 1],
    "CI_up" = conf_intervals[, 2]
  )
  return(est_df)
})
stopCluster(cl)

```


```{r}
estisimule <- full_mcar_mar(True = beta, nsim =nsim,  hat_estimate = Full.est)
round(estisimule,3)
```



## completes cases analysis (MCAR)

```{r}
cl <- makeCluster(detectCores())
clusterExport(cl, c("datas"))
invisible(clusterCall(cl, PACKAGE, c("survival")))
MCAR.mod <- parLapply(cl, datas, function(data) {
  coxph(Surv(time, delta=="1") ~ X1.mis + X2 + X3,na.action = na.omit, data = data)
})

MCAR.est <- parLapply(cl, MCAR.mod, function(model) {
  coef <- model$coefficients
  conf_intervals <- confint(model)
  est_df <- data.frame(
    "Estimate" = coef,
    "CI_low" = conf_intervals[, 1],
    "CI_up" = conf_intervals[, 2]
  )
  return(est_df)
})
stopCluster(cl) 
```



```{r}
estimcar <- full_mcar_mar(True = beta,nsim =nsim, hat_estimate = MCAR.est)
row.names(estimcar) <- rownames(estisimule)
round(estimcar,3)
```




## Imputation paramétrique avec le package mice (MAR)

```{r}
M = 20 # Nombre d'imputations

cl <- makeCluster(detectCores())
clusterExport(cl, c("datas", "M")) 
invisible(clusterCall(cl, PACKAGE, c("mice")))
mice_P_data <- parLapply(cl, 1:nsim, function(s) {
  mice(
    data= datas[[s]][,c("cumhaz", "delta", "X1.mis","X2","X3")],  
    m = M,         
    maxit = 10,      
    method = c("norm","logreg", "polyreg","logreg","norm"),
    print = FALSE,
    seed = 10000
  )
})

stopCluster(cl)
```



```{r}
mice_P_data <- lapply(1:nsim, function(s) {
  # Créer une liste de jeux de données combinés pour chaque imputation
  combined_data <- lapply(1:M, function(m) {
    cbind("time"= datas[[s]]$time, mice::complete(mice_P_data[[s]], m))
  })
  
  # Convertir la liste de données en un objet mids
  mitml_object <- mitml::as.mitml.list(combined_data)
  
  return(mitml_object)
})

```






```{r}
compute_mar <- function(data){
  mar.model <- with(data, coxph(Surv(time, delta =="1") ~ X1.mis + X2 +X3 ))
  mar.est <- data.frame(
    cbind(summary(mice::pool(mar.model), conf.int = TRUE)[, c("estimate", "2.5 %", "97.5 %")]))
  colnames(mar.est) <- c("Estimate",  "CI_low", "CI_up")
  return(mar.est)
}
```



```{r}

cl <- makeCluster(detectCores())
clusterExport(cl, c("mice_P_data","compute_mar"))
invisible(clusterCall(cl, PACKAGE, c("survival","mice","mitml")))
tout_mice.est <- parLapply(cl,  1:nsim, function(s){
  compute_mar(data = mice_P_data[[s]])
})
stopCluster(cl)


estimar_P_mice <- full_mcar_mar(True = beta,nsim = nsim, hat_estimate = tout_mice.est)
row.names(estimar_P_mice) <- rownames(estisimule)
round(estimar_P_mice,3)

```


## Approche semi-paramétrique: inverse de la probabilité pondérée (MAR)

### Paramètre de compromis

```{r}
 kappa = 1 
# kappa = 0.95
# kappa = 0.9
# kappa = 0.7
# kappa = 0.5
# kappa = 0
```


```{r}

datas <- lapply(1:nsim, function(s) {
  work.model <- glm(R ~ time + delta + X2 + X3, data = datas[[s]], family = binomial)
  predicted <-  pmax(pmin(predict(work.model, type = "response"), 0.99), 0.01)
  datas[[s]]$w <- ifelse(
    datas[[s]]$R == 1,
    1 / predicted, 
    kappa*1 + (1-kappa)*(1 / (1-predicted))
  )
  
  return(datas[[s]])
})
```


```{r}
cl <- makeCluster(detectCores())
clusterExport(cl, c("datas"))
invisible(clusterCall(cl, PACKAGE, c("survival")))
iwp.mod <- parLapply(cl, datas, function(data) {
  coxph(Surv(time, delta=="1") ~ X1.mis + X2 + X3,weights =w, data = data,robust = TRUE)
})

iwp.est <- parLapply(cl, iwp.mod, function(model) {
  coef <- model$coefficients
  conf_intervals <- confint(model)
  est_df <- data.frame(
    "Estimate" = coef,
    "CI_low" = conf_intervals[, 1],
    "CI_up" = conf_intervals[, 2]
  )
  return(est_df)
})
stopCluster(cl)
```



```{r}
estimar_iwp <- full_mcar_mar(True = beta,nsim = nsim, hat_estimate = iwp.est)
row.names(estimar_iwp) <- rownames(estisimule)
round(estimar_iwp,3)
```




## Imputatiion non paramétrique : Random forest (MAR)



```{r}
cl <- makeCluster(detectCores())
clusterExport(cl, c("datas", "M")) 
invisible(clusterCall(cl, PACKAGE, c("mice","ranger")))
mice.rf.data <- parLapply(cl, 1:nsim, function(s) {
  mice(
    data= datas[[s]][,c("time", "delta", "X1.mis","X2","X3")],  
    m = M,         
    maxit = 10,      
    method = c("rf","rf", "rf","rf","rf"), 
    print = FALSE,
    seed = 10000
  )
})

stopCluster(cl)
```





```{r}
cl <- makeCluster(detectCores())
clusterExport(cl, c("mice.rf.data","compute_mar"))
invisible(clusterCall(cl, PACKAGE, c("survival","mice","ranger")))
tout_mice.rf.est <- parLapply(cl,  1:nsim, function(s){
  compute_mar(data = mice.rf.data[[s]])
})
stopCluster(cl)

```




```{r}
estimar_mice_RF_NP <- full_mcar_mar(True = beta,nsim = nsim, hat_estimate = tout_mice.rf.est)
row.names(estimar_mice_RF_NP) <- rownames(estisimule)
round(estimar_mice_RF_NP,3)
```



## Méthodes hybrides 

### Hybride 1:  MI paramétrique  et  MI non paramétrique (MAR)


```{r}
P_NP_data <- lapply(1:nsim, function(s) {
  temp_data <- vector("list", M)
  for (i in 1:(M/2)) {
    temp_data[[i]] <- mice_P_data[[s]][[i]]
    temp_data[[i + (M/2)]] <- mice::complete(mice.rf.data[[s]], i)
  }
  temp_data <- mitml::as.mitml.list(temp_data)
  temp_data
})
```




```{r}
cl <- makeCluster(detectCores())
clusterExport(cl, c("P_NP_data","compute_mar"))
invisible(clusterCall(cl, PACKAGE, c("survival","mice", "mitml","ranger")))
tout_P_NP.est <- parLapply(cl,  1: nsim, function(s){
  compute_mar(data = P_NP_data[[s]])
})
stopCluster(cl)

```


```{r}
estimar_mice_P_NP <- full_mcar_mar(True = beta,nsim = nsim, hat_estimate = tout_P_NP.est)
row.names(estimar_mice_P_NP ) <- rownames(estisimule)
round(estimar_mice_P_NP,3)
```




### Hybride 2: MI paramétrique et IWP (MAR)



```{r}
MI.P_IWP_data <- lapply(1:nsim, function(s) {
  imputation <- lapply(1:M, function(m) {
    cbind(mice_P_data[[s]][[m]],
          datas[[s]][, c("R", "w")]
    )
  })
})
MI.P_IWP_data <- lapply(1:nsim, function(s) {
  mitml::as.mitml.list(MI.P_IWP_data[[s]])
})
```




```{r}
compute_MI_IWP <- function(data_list) {
  # Initialiser des vecteurs pour stocker les estimations, les variances robustes et les IC
  estimates <- list()
  robust_variances <- list()
  
  # Parcourir chaque jeu d'imputation
  for (i in seq_along(data_list)) {
    # Ajuster le modèle de Cox pour chaque jeu de données imputé
    fit <- coxph(Surv(time, delta == "1") ~ X1.mis + X2 + X3, 
                 data = data_list[[i]], weights = data_list[[i]]$w,robust = TRUE)
    
    # Stocker les estimations
    estimates[[i]] <- coef(fit)  # Coefficients estimés
    
    # Calculer et stocker les variances robustes
    robust_variances[[i]] <- diag(vcov(fit, robust = TRUE))  # Variances robustes des coefficients estimés
  }
  
  # Convertir les résultats en matrices pour faciliter les calculs
  estimates_mat <- do.call(rbind, estimates)
  robust_variances_mat <- do.call(rbind, robust_variances)
  
  # Nombre d'imputations
  m <- length(data_list)
  
  # Combiner les estimations et les variances avec la règle de Rubin
  Q_bar <- colMeans(estimates_mat)  # Moyenne des estimations
  U_bar <- colMeans(robust_variances_mat)  # Variance intra-imputation (robuste)
  B <- apply(estimates_mat, 2, var)*(m / (m - 1))  # Variance inter-imputation
  T <- U_bar + (1 + 1/m) * B  # Variance totale combinée
  
    # df: degrés de liberté de Rubin
   df <- (m - 1)*(1 + U_bar/B)^2

  # Calcul des erreurs standards et des IC combinés
   CI_low_combined <- Q_bar - qt(0.975, df = df) * sqrt(T)
   CI_up_combined <- Q_bar + qt(0.975, df = df) * sqrt(T)
  
  # Résultat final sous forme de data.frame
  mar.est <- data.frame(
    Estimate = Q_bar,
    CI_low = CI_low_combined,
    CI_up = CI_up_combined
  )
  return(mar.est)
}
```




```{r}
cl <- makeCluster(detectCores())
clusterExport(cl, c("MI.P_IWP_data","compute_MI_IWP"))
invisible(clusterCall(cl, PACKAGE, c("survival","mice","mitml")))
tout_miceP_iwp.est <- parLapply(cl,  1:nsim, function(s){
  compute_MI_IWP(data = MI.P_IWP_data[[s]])
})
stopCluster(cl)
```





```{r}
estimar_mice_P_iwp <- full_mcar_mar(True = beta,nsim = nsim, hat_estimate = tout_miceP_iwp.est)
row.names(estimar_mice_P_iwp) <- rownames(estisimule)
round(estimar_mice_P_iwp,3)
```



### Hybride 3: MI non paramétrique et IWP (MAR)



```{r}
MI.NP_IWP_data <- lapply(1:nsim, function(s) {
  lapply(1:M, function(m) {
    cbind(mice::complete(mice.rf.data[[s]], m),
          datas[[s]][, c("R", "w")]
    )
  })
})


MI.NP_IWP_data <- lapply(1:nsim, function(s) {
  mitml::as.mitml.list(MI.NP_IWP_data[[s]])
})

```





```{r}
cl <- makeCluster(detectCores())
clusterExport(cl, c("MI.NP_IWP_data","compute_MI_IWP"))
invisible(clusterCall(cl, PACKAGE, c("survival","mice","mitml","ranger")))
tout_miceNP_iwp.est <- parLapply(cl,  1:nsim, function(s){
  compute_MI_IWP(data = MI.NP_IWP_data[[s]])
})
stopCluster(cl)
```


```{r}
estimar_mice_NP_iwp <- full_mcar_mar(True = beta,nsim = nsim, hat_estimate = tout_miceNP_iwp.est)
row.names(estimar_mice_NP_iwp) <- rownames(estisimule)
round(estimar_mice_NP_iwp,3)

```


### Hybride 4: MI paramétrique, MI non paramétrique et IWP (MAR)


```{r}
P_NP_IWP_data <- lapply(1:nsim, function(s){
  lapply(1:M, function(m){
    cbind(P_NP_data[[s]][[m]],
          datas[[s]][, c("R", "w")])
  })
})

P_NP_IWP_data <- lapply(1:nsim, function(s) {
  mitml::as.mitml.list(P_NP_IWP_data[[s]])
})
```




```{r}
cl <- makeCluster(detectCores())
clusterExport(cl, c("P_NP_IWP_data","compute_MI_IWP"))
invisible(clusterCall(cl, PACKAGE, c("survival","mice","mitml","ranger")))
tout_mice_P_NP_iwp.est <- parLapply(cl,  1:nsim, function(s){
  compute_MI_IWP(data = P_NP_IWP_data[[s]])
})
stopCluster(cl)
```





```{r}
estimar_mice_P_NP_iwp <- full_mcar_mar(True = beta,nsim = nsim, hat_estimate = tout_mice_P_NP_iwp.est)
row.names(estimar_mice_P_NP_iwp) <- rownames(estisimule)
round(estimar_mice_P_NP_iwp,3)
```





# Résultats


```{r}
bias_relative <- function(value,hat_estimate){
  return(((hat_estimate - value)/value)*100)
}
```




## Les estimés


```{r}
all_estimate <- data.frame(True = beta,
                           Full = estisimule[,"Estimate"],
                           CC = estimcar[,"Estimate"],
                           Iwp = estimar_iwp[,"Estimate"],
                           Mice.P = estimar_P_mice[,"Estimate"],
                           RF.NP = estimar_mice_RF_NP[,"Estimate"],
                           Hybrid1 = estimar_mice_P_NP[,"Estimate"],
                           Hybrid2 = estimar_mice_P_iwp[,"Estimate"],
                           Hybrid3 = estimar_mice_NP_iwp[,"Estimate"],
                           Hybrid4 = estimar_mice_P_NP_iwp[,"Estimate"])
rownames(all_estimate) <- rownames(estisimule)
knitr::kable(round(all_estimate, 3))
```






## Biais relatif en pourcentage


```{r}
all_bias <- data.frame(Full = bias_relative(value = beta,hat_estimate = estisimule[,"Estimate"]),
                       CC = bias_relative(value = beta,hat_estimate = estimcar[,"Estimate"]),
                       Iwp = bias_relative(value = beta,hat_estimate = estimar_iwp[,"Estimate"]),
                       Mice.P = bias_relative(value = beta,hat_estimate = estimar_P_mice[,"Estimate"]),
                       RF.NP = bias_relative(value = beta,hat_estimate = estimar_mice_RF_NP[,"Estimate"]),
                       Hybrid1 = bias_relative(value = beta,hat_estimate = estimar_mice_P_NP[,"Estimate"]),
                       Hybrid2 = bias_relative(value = beta,hat_estimate = estimar_mice_P_iwp[,"Estimate"]),
                       Hybrid3 = bias_relative(value = beta,hat_estimate = estimar_mice_NP_iwp[,"Estimate"]),
                       Hybrid4 = bias_relative(value = beta,hat_estimate = estimar_mice_P_NP_iwp[,"Estimate"]))
rownames(all_bias) <- rownames(estisimule)


knitr::kable(round(all_bias,3))
```





## standard deviation

```{r}
all_sd <- data.frame(Full = estisimule[,"Emp_sd"],
                     CC = estimcar[,"Emp_sd"],
                     Iwp = estimar_iwp[,"Emp_sd"],
                     Mice.P = estimar_P_mice[,"Emp_sd"],
                     RF.NP = estimar_mice_RF_NP[,"Emp_sd"],
                     Hybrid1 = estimar_mice_P_NP[,"Emp_sd"],
                     Hybrid2 = estimar_mice_P_iwp[,"Emp_sd"],
                     Hybrid3 = estimar_mice_NP_iwp[,"Emp_sd"],
                     Hybrid4 = estimar_mice_P_NP_iwp[,"Emp_sd"])
rownames(all_sd) <- rownames(estisimule)

knitr::kable(round(all_sd,3))
```




## Coverage

```{r}
all_coverage <- data.frame(Full = estisimule[,"Cover"],
                           CC = estimcar[,"Cover"],
                           Iwp = estimar_iwp[,"Cover"],
                           Mice.P = estimar_P_mice[,"Cover"],
                           RF.NP = estimar_mice_RF_NP[,"Cover"],
                           Hybrid1 = estimar_mice_P_NP[,"Cover"],
                           Hybrid2 = estimar_mice_P_iwp[,"Cover"],
                           Hybrid3 = estimar_mice_NP_iwp[,"Cover"],
                           Hybrid4 = estimar_mice_P_NP_iwp[,"Cover"])

rownames(all_coverage) <- rownames(estisimule)

knitr::kable(all_coverage)
```




## Largeurs des intervalles de confiance

```{r}
all_CI_width <- data.frame(Full = estisimule[,"CI_width"],
                           CC = estimcar[,"CI_width"],
                           Iwp = estimar_iwp[,"CI_width"],
                           Mice.P = estimar_P_mice[,"CI_width"],
                           RF.NP = estimar_mice_RF_NP[,"CI_width"],
                           Hybrid1 = estimar_mice_P_NP[,"CI_width"],
                           Hybrid2= estimar_mice_P_iwp[,"CI_width"],
                           Hybrid3= estimar_mice_NP_iwp[,"CI_width"],
                           Hybrid4 = estimar_mice_P_NP_iwp[,"CI_width"])

rownames(all_CI_width) <- rownames(estisimule)

knitr::kable(round(all_CI_width,3))
```

## Réprésentation graphique


```{r}
biais_ci_coverage <- function(bias_data, ci_data, coverage_data) {
  # 1. Mise en forme des données
  method_order <- colnames(bias_data) # Capturer l'ordre des colonnes
  
  bias <- as.data.frame(bias_data) %>%
    dplyr::mutate(Variable = rownames(bias_data)) %>%
    tidyr::pivot_longer(-Variable, names_to = "Method", values_to = "Bias (%)")
  
  ci <- as.data.frame(ci_data) %>%
    dplyr::mutate(Variable = rownames(ci_data)) %>%
    tidyr::pivot_longer(-Variable, names_to = "Method", values_to = "CI Width (95%)")
  
  coverage <- as.data.frame(coverage_data) %>%
    dplyr::mutate(Variable = rownames(coverage_data)) %>%
    tidyr::pivot_longer(-Variable, names_to = "Method", values_to = "Coverage (%)")
  
  # 2. Fusionner les données pour un affichage cohérent
  all_data <- bias %>%
    dplyr::left_join(ci, by = c("Variable", "Method")) %>%
    dplyr::left_join(coverage, by = c("Variable", "Method")) %>%
    tidyr::pivot_longer(cols = c("Bias (%)", "CI Width (95%)", "Coverage (%)"),
                        names_to = "Metric", values_to = "Value")
  
  # 3. Forcer l'ordre des méthodes
  all_data <- all_data %>%
    dplyr::mutate(Method = factor(Method, levels = method_order)) # Ordre explicite des facteurs
  
  # 4. Générer le graphique
  plot <- ggplot2::ggplot(all_data, ggplot2::aes(x = Method, y = Value, fill = Method)) +
    ggplot2::geom_bar(stat = "identity", position = ggplot2::position_dodge(width = 2)) +
    ggplot2::facet_grid(Metric ~ Variable, scales = "free_y") +
    ggplot2::theme_bw(base_size = 8) +
    ggplot2::labs(
      title = "Relative Bias (%), CI Width (95%), and Coverage (%) --- (Scenario 1)",
      x = "",
      y = "Values"
    ) +
    ggplot2::theme(
      legend.position = "right",
      plot.title = ggplot2::element_text(hjust = 0.5),
      axis.text.x = ggplot2::element_text(angle = 45, hjust = 1)
    )
  
  return(plot)
}
```



```{r}
bias_data <- all_bias
colnames(bias_data) <- c("FULL", "CC", "IWP", "MICE.P", "RF.NP", "HYBRID1", "HYBRID2","HYBRID3" ,  "HYBRID4")
rownames(bias_data) <- c("beta12", "beta13", "beta21", "beta3")

ci_data <- all_CI_width
colnames(ci_data) <- colnames(bias_data)
rownames(ci_data) <- rownames(bias_data)

coverage_data <- all_coverage
colnames(coverage_data) <- colnames(bias_data)
rownames(coverage_data) <- rownames(bias_data)

```

```{r}
biais_ci_coverage(bias_data, ci_data, coverage_data)
```


```{r}
tf <- Sys.time()
code_time = tf - ti
code_time
```


# sink()


